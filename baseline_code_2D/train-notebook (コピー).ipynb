{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting and Load library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# python default library\n",
    "############################################################################\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "############################################################################\n",
    "############################################################################\n",
    "# additional library\n",
    "############################################################################\n",
    "# general analysis tool-kit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sound analysis tool-kit\n",
    "import librosa\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch import optim, nn\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "# pytorch ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "\n",
    "# deeplearning tool-kit\n",
    "from torchvision import transforms\n",
    "\n",
    "# etc\n",
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "############################################################################\n",
    "# original library\n",
    "############################################################################\n",
    "import common as com\n",
    "from pytorch_model import AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting I/O path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_path = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_path = INPUT_ROOT + \"/add_dev_data\"\n",
    "eval_test_path = INPUT_ROOT + \"/eval_test\"\n",
    "# machine type\n",
    "machine_types = os.listdir(dev_path)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_paths = {}\n",
    "dev_test_paths = {}\n",
    "add_train_paths = {}\n",
    "add_test_paths = {}\n",
    "eval_test_paths = {}\n",
    "\n",
    "for machine_type in enumerate(machine_types):\n",
    "    \n",
    "    dev_train_all_paths = [\"{}/{}/train/\".format(dev_path, machine_type) + \n",
    "                           file for file in os.listdir(\"{}/{}/train\".format(dev_path, machine_type))]\n",
    "    dev_train_paths[machine_type] = {}\n",
    "    dev_train_paths[machine_type]['train'], \n",
    "    dev_train_paths[machine_type]['valid'] = train_test_split(dev_train_all_paths,\n",
    "                                                              test_size=config['eval_param']['test_size'],\n",
    "                                                              random_state=config['eval_param']['random_state'])\n",
    "    #dev_test_paths[machine_type] = [\"{}/{}/test/\".format(dev_path, machine_type) + \n",
    "    #                                 file for file in os.listdir(\"{}/{}/test\".format(dev_path, machine_type))]\n",
    "    add_train_paths[machine_type] = [\"{}/{}/train/\".format(add_dev_path, machine_type) + \n",
    "                                     file for file in os.listdir(\"{}/{}/train\".format(add_dev_path, machine_type))]\n",
    "    #add_test_paths[machine_type] = [\"{}/{}/test/\".format(add_dev_path, machine_type) + \n",
    "    #                                 file for file in os.listdir(\"{}/{}/test\".format(add_dev_path, machine_type))]\n",
    "    #eval_test_paths[machine_type] = [\"{}/{}/test/\".format(eval_test_path, machine_type) + \n",
    "    #                                 file for file in os.listdir(\"{}/{}/test\".format(eval_test_path, machine_type))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine_type in machine_types:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3291"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_train_paths[machine_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav_to_Melspectrogram(object):\n",
    "    \"\"\"\n",
    "    wavデータロード(波形) -> ログメルスペクトログラム\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    dims = n_mels * frames\n",
    "    sound_data : numpy.ndarray.shape = (timecourse, dims)\n",
    "    \"\"\"\n",
    "    def __init__(self, sound_data=None):\n",
    "        self.sound_data = sound_data\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        self.sound_data = com.file_to_vector_array(\n",
    "            sample['wav_name'],\n",
    "            config['mel_spectrogram_param']['n_mels'],\n",
    "            config['mel_spectrogram_param']['frames'],\n",
    "            config['mel_spectrogram_param']['n_fft'],\n",
    "            config['mel_spectrogram_param']['hop_length'],\n",
    "            config['mel_spectrogram_param']['power']\n",
    "        )\n",
    "        self.labels = np.full((self.sound_data.shape[0]), sample['label'])\n",
    "        return {'features': self.sound_data, 'labels': self.labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        features, labels = sample['features'], sample['labels']\n",
    "        \n",
    "        return {'features': torch.from_numpy(features), 'labels': torch.from_numpy(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCASE_task2_Dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Attribute\n",
    "    ----------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_list = file_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        # ファイル名でlabelを判断\n",
    "        if \"normal\" in file_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        sample = {'wav_name':file_path, 'label':label}\n",
    "        sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    Wav_to_Melspectrogram(),\n",
    "    ToTensor()\n",
    "])\n",
    "train_dataset = DCASE_task2_Dataset(dev_train_paths[machine_types[0]], transform=transform)\n",
    "#valid_dataset = DCASE_task2_Dataset(dev_valid_paths[machine_types[0]], transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config['fit']['batch_size'],\n",
    "    shuffle=config['fit']['shuffle'],\n",
    "    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=config['fit']['batch_size'],\n",
    "    shuffle=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([309, 640])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AutoEncoder()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, train_loader, valid_loader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"use:\", device)\n",
    "    net.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('----------------------')\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            \n",
    "            epoch_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
