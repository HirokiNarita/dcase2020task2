{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show reconstruct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiroki/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# load config\n",
    "########################################################################\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting I/O path\n",
    "########################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_path = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_path = INPUT_ROOT + \"/add_dev_data\"\n",
    "eval_path = INPUT_ROOT + \"/eval_test\"\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "# machine type\n",
    "MACHINE_TYPE = config['IO_OPTION']['MACHINE_TYPE']\n",
    "machine_types = os.listdir(dev_path)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "RESULT_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/result'\n",
    "RECONS_OUTDIR = OUTPUT_ROOT +'/eval_reconstruct_img'\n",
    "PKL_DIR = OUTPUT_ROOT +'/pkl'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import itertools\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "import common as com\n",
    "import pytorch_modeler as modeler\n",
    "from pytorch_model import DAGMM as Model\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "########################################################################\n",
    "import eval_functions as eval_func\n",
    "from pytorch_utils import to_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiroki/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# load config\n",
    "########################################################################\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting seed\n",
    "########################################################################\n",
    "modeler.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting I/O path\n",
    "########################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_path = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_path = INPUT_ROOT + \"/add_dev_data\"\n",
    "eval_path = INPUT_ROOT + \"/eval_test\"\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "# machine type\n",
    "MACHINE_TYPE = config['IO_OPTION']['MACHINE_TYPE']\n",
    "machine_types = os.listdir(dev_path)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "RESULT_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/result'\n",
    "RECONS_OUTDIR = OUTPUT_ROOT +'/eval_reconstruct_img'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# for original function\n",
    "########################################################################\n",
    "param = {}\n",
    "param[\"dev_directory\"] = dev_path\n",
    "param[\"eval_directory\"] = eval_path\n",
    "param[\"model_directory\"] = MODEL_DIR\n",
    "param[\"result_directory\"] = RESULT_DIR\n",
    "param[\"result_file\"] = 'result.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def calc_time_anomaly(x, y, label, file_name):\n",
    "    fig = plt.figure(figsize=(10,5)) # width, height\n",
    "    fig.suptitle('label={}'.format(int(label)))\n",
    "    time_anomaly = np.zeros((x.shape[0]))\n",
    "    for frame in range(x.shape[0]):\n",
    "        time_anomaly[frame] = mse(y[frame,:],x[frame,:])\n",
    "    plt.plot(time_anomaly)\n",
    "    plt.title(f'label:{label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_anomaly.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(time_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(np.abs(x-y), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reconstruct_img(x, y, label, file_name):\n",
    "    fig = plt.figure(figsize=(10,5)) # width, height\n",
    "    fig.suptitle('label={}'.format(int(label)))\n",
    "    ax1 = fig.add_subplot(121, title='x') # 明示的にAxesを作成する\n",
    "    sns.heatmap(x.T, ax=ax1) # ax1を参照するようにする\n",
    "    ax2 = fig.add_subplot(122, title='y')\n",
    "    sns.heatmap(y.T, ax=ax2)\n",
    "    fig.savefig('{}.png'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import preprocessing as prep\n",
    "\n",
    "class extract_waveform(object):\n",
    "    \"\"\"\n",
    "    wavデータロード(波形)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    sound_data : waveform\n",
    "    \"\"\"\n",
    "    def __init__(self, sound_data=None):\n",
    "        self.sound_data = sound_data\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        self.sound_data = com.file_load(sample['wav_name'],\n",
    "                                        sr=config['preprocessing']['sample_rate'],\n",
    "                                        mono=config['preprocessing']['mono'])\n",
    "        self.sound_data = self.sound_data[0]\n",
    "        self.label = np.array(sample['label'])\n",
    "        self.wav_name = sample['wav_name']\n",
    "        \n",
    "        return {'feature': self.sound_data, 'label': self.label, 'wav_name': self.wav_name}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label, wav_name = sample['feature'], sample['label'], sample['wav_name']\n",
    "        \n",
    "        return {'feature': torch.from_numpy(feature).float(), 'label': torch.from_numpy(label), 'wav_name': wav_name}\n",
    "\n",
    "class DCASE_task2_Dataset_test(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Attribute\n",
    "    ----------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_list = file_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        # ファイル名でlabelを判断\n",
    "        if \"normal\" in file_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        sample = {'wav_name':file_path, 'label':np.array(label)}\n",
    "        sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "def make_dataloader_train(paths):\n",
    "    transform = transforms.Compose([\n",
    "        extract_waveform(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    dataset = DCASE_task2_Dataset_test(paths, transform=transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config['fit']['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return test_loader\n",
    "    \n",
    "def make_dataloader_test(paths):\n",
    "    transform = transforms.Compose([\n",
    "        extract_waveform(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    dataset = DCASE_task2_Dataset_test(paths, transform=transform)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config['fit']['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# make path set and train/valid split\n",
    "############################################################################\n",
    "'''\n",
    "train_paths[machine_type]['train' or 'valid'] = path\n",
    "'''\n",
    "dev_train_paths = {}\n",
    "add_train_paths = {}\n",
    "train_paths = {}\n",
    "\n",
    "for machine_type in machine_types:\n",
    "    # dev train\n",
    "    dev_train_paths = [\"{}/{}/train/\".format(dev_path, machine_type) + file for file in os.listdir(\"{}/{}/train\".format(dev_path, machine_type))]\n",
    "    dev_train_paths = sorted(dev_train_paths)\n",
    "    # add_dev train\n",
    "    add_train_paths = [\"{}/{}/train/\".format(add_dev_path, machine_type) + file for file in os.listdir(\"{}/{}/train\".format(add_dev_path, machine_type))]\n",
    "    add_train_paths = sorted(add_train_paths)\n",
    "    # valid\n",
    "    dev_valid_paths = [\"{}/{}/test/\".format(dev_path, machine_type) + file for file in os.listdir(\"{}/{}/test\".format(dev_path, machine_type))]\n",
    "    dev_valid_paths = sorted(dev_valid_paths)\n",
    "    \n",
    "    train_paths[machine_type] = {}\n",
    "    train_paths[machine_type]['train'] = dev_train_paths + add_train_paths\n",
    "    train_paths[machine_type]['valid'] = dev_valid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 18:13:32,777 - INFO - load_directory <- development\n",
      "2020-11-30 18:13:32,779 - INFO - ===========================\n",
      "2020-11-30 18:13:32,779 - INFO - [1/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar\n",
      "2020-11-30 18:13:32,780 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:13:33,716 - INFO - ============== CALC GMM PARAM : ToyCar ==============\n",
      "100%|██████████| 55/55 [00:05<00:00, 10.50it/s]\n",
      "2020-11-30 18:13:38,959 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_01\n",
      "2020-11-30 18:13:38,966 - INFO - test_file  num : 601\n",
      "2020-11-30 18:13:38,967 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 7000\n",
      "phi :\n",
      " tensor([3.3541e-05, 9.9992e-01, 4.3399e-05])\n",
      "mu :\n",
      " tensor([[ 0.0985, -0.0885,  0.0955, -0.1044, -0.1037,  0.2007],\n",
      "        [-0.0246,  0.0311, -0.0232,  0.0162,  0.0272,  0.0713],\n",
      "        [ 0.1417, -0.1353,  0.1362, -0.1435, -0.1439,  0.2440]])\n",
      "cov :\n",
      " tensor([[[ 0.0545, -0.0517,  0.0499, -0.0510, -0.0510,  0.0513],\n",
      "         [-0.0517,  0.0542, -0.0513,  0.0513,  0.0513, -0.0513],\n",
      "         [ 0.0499, -0.0513,  0.0548, -0.0503, -0.0523,  0.0514],\n",
      "         [-0.0510,  0.0513, -0.0503,  0.0553,  0.0513, -0.0514],\n",
      "         [-0.0510,  0.0513, -0.0523,  0.0513,  0.0549, -0.0514],\n",
      "         [ 0.0513, -0.0513,  0.0514, -0.0514, -0.0514,  0.0570]],\n",
      "\n",
      "        [[ 0.0065, -0.0035,  0.0019, -0.0027, -0.0029,  0.0016],\n",
      "         [-0.0035,  0.0057, -0.0031,  0.0029,  0.0030, -0.0015],\n",
      "         [ 0.0019, -0.0031,  0.0067, -0.0021, -0.0038,  0.0016],\n",
      "         [-0.0027,  0.0029, -0.0021,  0.0072,  0.0031, -0.0015],\n",
      "         [-0.0029,  0.0030, -0.0038,  0.0031,  0.0065, -0.0016],\n",
      "         [ 0.0016, -0.0015,  0.0016, -0.0015, -0.0016,  0.0018]],\n",
      "\n",
      "        [[ 0.0585, -0.0557,  0.0546, -0.0554, -0.0554,  0.0584],\n",
      "         [-0.0557,  0.0578, -0.0557,  0.0555,  0.0554, -0.0583],\n",
      "         [ 0.0546, -0.0557,  0.0588, -0.0547, -0.0564,  0.0585],\n",
      "         [-0.0554,  0.0555, -0.0547,  0.0595,  0.0555, -0.0584],\n",
      "         [-0.0554,  0.0554, -0.0564,  0.0555,  0.0588, -0.0585],\n",
      "         [ 0.0584, -0.0583,  0.0585, -0.0584, -0.0585,  0.0653]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.90it/s]\n",
      "2020-11-30 18:13:39,990 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyCar_id_01.csv\n",
      "2020-11-30 18:13:39,994 - INFO - AUC : 0.5487877063175868\n",
      "2020-11-30 18:13:39,994 - INFO - pAUC : 0.5305994068837432\n",
      "2020-11-30 18:13:39,995 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:39,996 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_02\n",
      "2020-11-30 18:13:40,004 - INFO - test_file  num : 602\n",
      "2020-11-30 18:13:40,005 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.85it/s]\n",
      "2020-11-30 18:13:40,864 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyCar_id_02.csv\n",
      "2020-11-30 18:13:40,867 - INFO - AUC : 0.5693310657596372\n",
      "2020-11-30 18:13:40,867 - INFO - pAUC : 0.5479174125790667\n",
      "2020-11-30 18:13:40,868 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:40,868 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_03\n",
      "2020-11-30 18:13:40,876 - INFO - test_file  num : 602\n",
      "2020-11-30 18:13:40,877 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.32it/s]\n",
      "2020-11-30 18:13:41,671 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyCar_id_03.csv\n",
      "2020-11-30 18:13:41,674 - INFO - AUC : 0.69578231292517\n",
      "2020-11-30 18:13:41,675 - INFO - pAUC : 0.5898675259577515\n",
      "2020-11-30 18:13:41,675 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:41,676 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_04\n",
      "2020-11-30 18:13:41,685 - INFO - test_file  num : 602\n",
      "2020-11-30 18:13:41,685 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.38it/s]\n",
      "2020-11-30 18:13:42,473 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyCar_id_04.csv\n",
      "2020-11-30 18:13:42,476 - INFO - AUC : 0.5758956916099773\n",
      "2020-11-30 18:13:42,477 - INFO - pAUC : 0.5433225921947726\n",
      "2020-11-30 18:13:42,477 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:42,478 - INFO - ===========================\n",
      "2020-11-30 18:13:42,479 - INFO - [2/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor\n",
      "2020-11-30 18:13:42,480 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:13:43,354 - INFO - ============== CALC GMM PARAM : ToyConveyor ==============\n",
      "100%|██████████| 47/47 [00:04<00:00, 11.16it/s]\n",
      "2020-11-30 18:13:47,570 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_01\n",
      "2020-11-30 18:13:47,580 - INFO - test_file  num : 1181\n",
      "2020-11-30 18:13:47,581 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 6000\n",
      "phi :\n",
      " tensor([1.2804e-04, 9.9981e-01, 5.7611e-05])\n",
      "mu :\n",
      " tensor([[-0.5070,  0.4904, -0.5016, -0.4833, -0.4816,  0.1463],\n",
      "        [ 0.0299, -0.0248,  0.0204,  0.0283,  0.0233,  0.0723],\n",
      "        [-0.1660,  0.1743, -0.1719, -0.1711, -0.1679,  0.2665]])\n",
      "cov :\n",
      " tensor([[[ 0.0431, -0.0422,  0.0427,  0.0427,  0.0425, -0.0336],\n",
      "         [-0.0422,  0.0436, -0.0433, -0.0418, -0.0429,  0.0336],\n",
      "         [ 0.0427, -0.0433,  0.0441,  0.0422,  0.0434, -0.0336],\n",
      "         [ 0.0427, -0.0418,  0.0422,  0.0436,  0.0420, -0.0336],\n",
      "         [ 0.0425, -0.0429,  0.0434,  0.0420,  0.0438, -0.0336],\n",
      "         [-0.0336,  0.0336, -0.0336, -0.0336, -0.0336,  0.0337]],\n",
      "\n",
      "        [[ 0.0046, -0.0024,  0.0028,  0.0034,  0.0026, -0.0014],\n",
      "         [-0.0024,  0.0064, -0.0048, -0.0015, -0.0044,  0.0016],\n",
      "         [ 0.0028, -0.0048,  0.0059,  0.0015,  0.0045, -0.0016],\n",
      "         [ 0.0034, -0.0015,  0.0015,  0.0063,  0.0015, -0.0014],\n",
      "         [ 0.0026, -0.0044,  0.0045,  0.0015,  0.0063, -0.0016],\n",
      "         [-0.0014,  0.0016, -0.0016, -0.0014, -0.0016,  0.0016]],\n",
      "\n",
      "        [[ 0.0558, -0.0539,  0.0543,  0.0545,  0.0542, -0.0536],\n",
      "         [-0.0539,  0.0577, -0.0563, -0.0528, -0.0559,  0.0537],\n",
      "         [ 0.0543, -0.0563,  0.0573,  0.0529,  0.0560, -0.0538],\n",
      "         [ 0.0545, -0.0528,  0.0529,  0.0570,  0.0529, -0.0536],\n",
      "         [ 0.0542, -0.0559,  0.0560,  0.0529,  0.0575, -0.0538],\n",
      "         [-0.0536,  0.0537, -0.0538, -0.0536, -0.0538,  0.0544]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.02it/s]\n",
      "2020-11-30 18:13:48,831 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyConveyor_id_01.csv\n",
      "2020-11-30 18:13:48,835 - INFO - AUC : 0.5018996062992126\n",
      "2020-11-30 18:13:48,836 - INFO - pAUC : 0.4976516093383064\n",
      "2020-11-30 18:13:48,836 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:48,838 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_02\n",
      "2020-11-30 18:13:48,848 - INFO - test_file  num : 1136\n",
      "2020-11-30 18:13:48,850 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.33it/s]\n",
      "2020-11-30 18:13:50,083 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyConveyor_id_02.csv\n",
      "2020-11-30 18:13:50,086 - INFO - AUC : 0.2644419642857143\n",
      "2020-11-30 18:13:50,086 - INFO - pAUC : 0.47824639724310775\n",
      "2020-11-30 18:13:50,087 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:50,087 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_03\n",
      "2020-11-30 18:13:50,099 - INFO - test_file  num : 1135\n",
      "2020-11-30 18:13:50,100 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.50it/s]\n",
      "2020-11-30 18:13:51,304 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_ToyConveyor_id_03.csv\n",
      "2020-11-30 18:13:51,307 - INFO - AUC : 0.5418976101078729\n",
      "2020-11-30 18:13:51,308 - INFO - pAUC : 0.49032468530525314\n",
      "2020-11-30 18:13:51,308 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:51,308 - INFO - ===========================\n",
      "2020-11-30 18:13:51,309 - INFO - [3/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan\n",
      "2020-11-30 18:13:51,309 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:13:52,122 - INFO - ============== CALC GMM PARAM : fan ==============\n",
      "100%|██████████| 51/51 [00:04<00:00, 10.87it/s]\n",
      "2020-11-30 18:13:56,820 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_00\n",
      "2020-11-30 18:13:56,826 - INFO - test_file  num : 489\n",
      "2020-11-30 18:13:56,827 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 6521\n",
      "phi :\n",
      " tensor([6.1461e-04, 4.1947e-03, 9.9519e-01])\n",
      "mu :\n",
      " tensor([[-0.2808,  0.2429,  0.2806,  0.0402,  0.2839,  0.1863],\n",
      "        [-0.2550,  0.2073,  0.2968,  0.2404,  0.3633,  0.1132],\n",
      "        [-0.0101,  0.0113,  0.0084, -0.0255,  0.0185,  0.0505]])\n",
      "cov :\n",
      " tensor([[[ 0.0107, -0.0093, -0.0095,  0.0085, -0.0080,  0.0074],\n",
      "         [-0.0093,  0.0107,  0.0103, -0.0084,  0.0101, -0.0070],\n",
      "         [-0.0095,  0.0103,  0.0125, -0.0068,  0.0121, -0.0078],\n",
      "         [ 0.0085, -0.0084, -0.0068,  0.0140, -0.0042,  0.0064],\n",
      "         [-0.0080,  0.0101,  0.0121, -0.0042,  0.0143, -0.0079],\n",
      "         [ 0.0074, -0.0070, -0.0078,  0.0064, -0.0079,  0.0089]],\n",
      "\n",
      "        [[ 0.0076, -0.0076, -0.0069,  0.0097, -0.0073,  0.0024],\n",
      "         [-0.0076,  0.0119,  0.0118, -0.0100,  0.0137, -0.0022],\n",
      "         [-0.0069,  0.0118,  0.0131, -0.0078,  0.0156, -0.0023],\n",
      "         [ 0.0097, -0.0100, -0.0078,  0.0179, -0.0071,  0.0023],\n",
      "         [-0.0073,  0.0137,  0.0156, -0.0071,  0.0200, -0.0023],\n",
      "         [ 0.0024, -0.0022, -0.0023,  0.0023, -0.0023,  0.0026]],\n",
      "\n",
      "        [[ 0.0070, -0.0042, -0.0059,  0.0038, -0.0062,  0.0027],\n",
      "         [-0.0042,  0.0069,  0.0024, -0.0042,  0.0044, -0.0033],\n",
      "         [-0.0059,  0.0024,  0.0070, -0.0045,  0.0057, -0.0029],\n",
      "         [ 0.0038, -0.0042, -0.0045,  0.0056, -0.0043,  0.0033],\n",
      "         [-0.0062,  0.0044,  0.0057, -0.0043,  0.0060, -0.0029],\n",
      "         [ 0.0027, -0.0033, -0.0029,  0.0033, -0.0029,  0.0039]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.05it/s]\n",
      "2020-11-30 18:13:57,491 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_fan_id_00.csv\n",
      "2020-11-30 18:13:57,494 - INFO - AUC : 0.816478149100257\n",
      "2020-11-30 18:13:57,494 - INFO - pAUC : 0.5583818157218239\n",
      "2020-11-30 18:13:57,495 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:57,495 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_02\n",
      "2020-11-30 18:13:57,502 - INFO - test_file  num : 441\n",
      "2020-11-30 18:13:57,502 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.35it/s]\n",
      "2020-11-30 18:13:58,136 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_fan_id_02.csv\n",
      "2020-11-30 18:13:58,139 - INFO - AUC : 0.6004985337243401\n",
      "2020-11-30 18:13:58,140 - INFO - pAUC : 0.7075165920666769\n",
      "2020-11-30 18:13:58,140 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:58,141 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_04\n",
      "2020-11-30 18:13:58,148 - INFO - test_file  num : 430\n",
      "2020-11-30 18:13:58,150 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.54it/s]\n",
      "2020-11-30 18:13:58,765 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_fan_id_04.csv\n",
      "2020-11-30 18:13:58,769 - INFO - AUC : 0.5212424242424243\n",
      "2020-11-30 18:13:58,770 - INFO - pAUC : 0.5137161084529506\n",
      "2020-11-30 18:13:58,770 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:58,771 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_06\n",
      "2020-11-30 18:13:58,777 - INFO - test_file  num : 443\n",
      "2020-11-30 18:13:58,778 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.35it/s]\n",
      "2020-11-30 18:13:59,412 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_fan_id_06.csv\n",
      "2020-11-30 18:13:59,415 - INFO - AUC : 0.758600583090379\n",
      "2020-11-30 18:13:59,416 - INFO - pAUC : 0.7873254564983889\n",
      "2020-11-30 18:13:59,416 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:13:59,417 - INFO - ===========================\n",
      "2020-11-30 18:13:59,417 - INFO - [4/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump\n",
      "2020-11-30 18:13:59,418 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:14:00,258 - INFO - ============== CALC GMM PARAM : pump ==============\n",
      "100%|██████████| 46/46 [00:04<00:00, 11.06it/s]\n",
      "2020-11-30 18:14:04,421 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_00\n",
      "2020-11-30 18:14:04,424 - INFO - test_file  num : 237\n",
      "2020-11-30 18:14:04,425 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 5766\n",
      "phi :\n",
      " tensor([9.4239e-05, 1.8104e-04, 9.9972e-01])\n",
      "mu :\n",
      " tensor([[ 0.2628, -0.3373,  0.1569,  0.3464, -0.2987,  0.1444],\n",
      "        [ 0.4178, -0.5877,  0.4706,  0.5951, -0.4816,  0.1104],\n",
      "        [ 0.0232, -0.0173, -0.0336,  0.0171, -0.0137,  0.0665]])\n",
      "cov :\n",
      " tensor([[[ 0.0742, -0.0783, -0.0484,  0.0819, -0.0801, -0.0249],\n",
      "         [-0.0783,  0.0873,  0.0459, -0.0890,  0.0878,  0.0250],\n",
      "         [-0.0484,  0.0459,  0.0591, -0.0507,  0.0515,  0.0258],\n",
      "         [ 0.0819, -0.0890, -0.0507,  0.0944, -0.0907, -0.0246],\n",
      "         [-0.0801,  0.0878,  0.0515, -0.0907,  0.0901,  0.0248],\n",
      "         [-0.0249,  0.0250,  0.0258, -0.0246,  0.0248,  0.0327]],\n",
      "\n",
      "        [[ 0.0264, -0.0286, -0.0138,  0.0298, -0.0289, -0.0059],\n",
      "         [-0.0286,  0.0331,  0.0124, -0.0333,  0.0327,  0.0058],\n",
      "         [-0.0138,  0.0124,  0.0206, -0.0141,  0.0149,  0.0064],\n",
      "         [ 0.0298, -0.0333, -0.0141,  0.0352, -0.0333, -0.0057],\n",
      "         [-0.0289,  0.0327,  0.0149, -0.0333,  0.0331,  0.0058],\n",
      "         [-0.0059,  0.0058,  0.0064, -0.0057,  0.0058,  0.0083]],\n",
      "\n",
      "        [[ 0.0069, -0.0056, -0.0042,  0.0058, -0.0058, -0.0014],\n",
      "         [-0.0056,  0.0072,  0.0050, -0.0063,  0.0073,  0.0015],\n",
      "         [-0.0042,  0.0050,  0.0058, -0.0053,  0.0049,  0.0016],\n",
      "         [ 0.0058, -0.0063, -0.0053,  0.0072, -0.0064, -0.0015],\n",
      "         [-0.0058,  0.0073,  0.0049, -0.0064,  0.0075,  0.0015],\n",
      "         [-0.0014,  0.0015,  0.0016, -0.0015,  0.0015,  0.0024]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.28it/s]\n",
      "2020-11-30 18:14:04,895 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_pump_id_00.csv\n",
      "2020-11-30 18:14:04,899 - INFO - AUC : 0.8621897810218978\n",
      "2020-11-30 18:14:04,901 - INFO - pAUC : 0.5420668459469843\n",
      "2020-11-30 18:14:04,901 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:04,902 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_02\n",
      "2020-11-30 18:14:04,906 - INFO - test_file  num : 205\n",
      "2020-11-30 18:14:04,907 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.85it/s]\n",
      "2020-11-30 18:14:05,322 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_pump_id_02.csv\n",
      "2020-11-30 18:14:05,325 - INFO - AUC : 0.7627619047619048\n",
      "2020-11-30 18:14:05,326 - INFO - pAUC : 0.6090225563909775\n",
      "2020-11-30 18:14:05,326 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:05,328 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_04\n",
      "2020-11-30 18:14:05,332 - INFO - test_file  num : 194\n",
      "2020-11-30 18:14:05,332 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\n",
      "2020-11-30 18:14:05,746 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_pump_id_04.csv\n",
      "2020-11-30 18:14:05,749 - INFO - AUC : 0.41595744680851066\n",
      "2020-11-30 18:14:05,749 - INFO - pAUC : 0.49720044792833146\n",
      "2020-11-30 18:14:05,750 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:05,750 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_06\n",
      "2020-11-30 18:14:05,755 - INFO - test_file  num : 196\n",
      "2020-11-30 18:14:05,755 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.78it/s]\n",
      "2020-11-30 18:14:06,176 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_pump_id_06.csv\n",
      "2020-11-30 18:14:06,180 - INFO - AUC : 0.31645833333333334\n",
      "2020-11-30 18:14:06,181 - INFO - pAUC : 0.47971491228070173\n",
      "2020-11-30 18:14:06,181 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:06,182 - INFO - ===========================\n",
      "2020-11-30 18:14:06,182 - INFO - [5/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider\n",
      "2020-11-30 18:14:06,183 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:14:07,042 - INFO - ============== CALC GMM PARAM : slider ==============\n",
      "100%|██████████| 41/41 [00:03<00:00, 10.85it/s]\n",
      "2020-11-30 18:14:10,824 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_00\n",
      "2020-11-30 18:14:10,828 - INFO - test_file  num : 445\n",
      "2020-11-30 18:14:10,829 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 5174\n",
      "phi :\n",
      " tensor([1.9411e-04, 9.9947e-01, 3.3641e-04])\n",
      "mu :\n",
      " tensor([[ 0.4109, -0.4050, -0.4106, -0.4106, -0.4181,  0.4649],\n",
      "        [-0.0315,  0.0209,  0.0201,  0.0276,  0.0190,  0.0546],\n",
      "        [ 0.4110, -0.4090, -0.4119, -0.4113, -0.4176,  0.4667]])\n",
      "cov :\n",
      " tensor([[[ 0.1332, -0.1307, -0.1311, -0.1320, -0.1324,  0.1302],\n",
      "         [-0.1307,  0.1336,  0.1307,  0.1305,  0.1290, -0.1293],\n",
      "         [-0.1311,  0.1307,  0.1333,  0.1311,  0.1298, -0.1298],\n",
      "         [-0.1320,  0.1305,  0.1311,  0.1338,  0.1328, -0.1300],\n",
      "         [-0.1324,  0.1290,  0.1298,  0.1328,  0.1331, -0.1294],\n",
      "         [ 0.1302, -0.1293, -0.1298, -0.1300, -0.1294,  0.1327]],\n",
      "\n",
      "        [[ 0.0056, -0.0037, -0.0030, -0.0039, -0.0054,  0.0031],\n",
      "         [-0.0037,  0.0067,  0.0026,  0.0031,  0.0029, -0.0027],\n",
      "         [-0.0030,  0.0026,  0.0068,  0.0028,  0.0021, -0.0028],\n",
      "         [-0.0039,  0.0031,  0.0028,  0.0061,  0.0058, -0.0028],\n",
      "         [-0.0054,  0.0029,  0.0021,  0.0058,  0.0068, -0.0031],\n",
      "         [ 0.0031, -0.0027, -0.0028, -0.0028, -0.0031,  0.0035]],\n",
      "\n",
      "        [[ 0.1292, -0.1269, -0.1271, -0.1279, -0.1283,  0.1264],\n",
      "         [-0.1269,  0.1294,  0.1265,  0.1267,  0.1254, -0.1256],\n",
      "         [-0.1271,  0.1265,  0.1294,  0.1271,  0.1258, -0.1261],\n",
      "         [-0.1279,  0.1267,  0.1271,  0.1296,  0.1286, -0.1263],\n",
      "         [-0.1283,  0.1254,  0.1258,  0.1286,  0.1289, -0.1257],\n",
      "         [ 0.1264, -0.1256, -0.1261, -0.1263, -0.1257,  0.1287]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.44it/s]\n",
      "2020-11-30 18:14:11,453 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_slider_id_00.csv\n",
      "2020-11-30 18:14:11,456 - INFO - AUC : 0.6200579710144928\n",
      "2020-11-30 18:14:11,457 - INFO - pAUC : 0.7351639969488941\n",
      "2020-11-30 18:14:11,457 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:11,458 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_02\n",
      "2020-11-30 18:14:11,463 - INFO - test_file  num : 356\n",
      "2020-11-30 18:14:11,464 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.49it/s]\n",
      "2020-11-30 18:14:12,014 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_slider_id_02.csv\n",
      "2020-11-30 18:14:12,018 - INFO - AUC : 0.4845703125\n",
      "2020-11-30 18:14:12,019 - INFO - pAUC : 0.6521381578947368\n",
      "2020-11-30 18:14:12,019 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:12,020 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_04\n",
      "2020-11-30 18:14:12,024 - INFO - test_file  num : 267\n",
      "2020-11-30 18:14:12,025 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.21it/s]\n",
      "2020-11-30 18:14:12,512 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_slider_id_04.csv\n",
      "2020-11-30 18:14:12,515 - INFO - AUC : 0.9005988023952095\n",
      "2020-11-30 18:14:12,515 - INFO - pAUC : 0.8751969744721084\n",
      "2020-11-30 18:14:12,516 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:12,516 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_06\n",
      "2020-11-30 18:14:12,521 - INFO - test_file  num : 178\n",
      "2020-11-30 18:14:12,522 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
      "2020-11-30 18:14:12,899 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_slider_id_06.csv\n",
      "2020-11-30 18:14:12,902 - INFO - AUC : 0.8042307692307693\n",
      "2020-11-30 18:14:12,903 - INFO - pAUC : 0.7139001349527665\n",
      "2020-11-30 18:14:12,903 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:12,904 - INFO - ===========================\n",
      "2020-11-30 18:14:12,904 - INFO - [6/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve\n",
      "2020-11-30 18:14:12,906 - INFO - ============== MODEL LOAD ==============\n",
      "2020-11-30 18:14:13,743 - INFO - ============== CALC GMM PARAM : valve ==============\n",
      "100%|██████████| 46/46 [00:04<00:00, 11.15it/s]\n",
      "2020-11-30 18:14:17,871 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_00\n",
      "2020-11-30 18:14:17,875 - INFO - test_file  num : 213\n",
      "2020-11-30 18:14:17,876 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 5822\n",
      "phi :\n",
      " tensor([0.0056, 0.0063, 0.9881])\n",
      "mu :\n",
      " tensor([[ 0.1357, -0.1275, -0.1340, -0.1349, -0.1271,  0.1523],\n",
      "        [ 0.1350, -0.1273, -0.1331, -0.1335, -0.1271,  0.1486],\n",
      "        [-0.0062,  0.0062,  0.0080,  0.0095,  0.0077,  0.0648]])\n",
      "cov :\n",
      " tensor([[[ 0.0661, -0.0619, -0.0661, -0.0670, -0.0629,  0.0356],\n",
      "         [-0.0619,  0.0582,  0.0617,  0.0627,  0.0588, -0.0335],\n",
      "         [-0.0661,  0.0617,  0.0666,  0.0673,  0.0631, -0.0356],\n",
      "         [-0.0670,  0.0627,  0.0673,  0.0684,  0.0635, -0.0363],\n",
      "         [-0.0629,  0.0588,  0.0631,  0.0635,  0.0603, -0.0341],\n",
      "         [ 0.0356, -0.0335, -0.0356, -0.0363, -0.0341,  0.0346]],\n",
      "\n",
      "        [[ 0.0649, -0.0609, -0.0649, -0.0657, -0.0618,  0.0341],\n",
      "         [-0.0609,  0.0574,  0.0607,  0.0615,  0.0579, -0.0321],\n",
      "         [-0.0649,  0.0607,  0.0652,  0.0659,  0.0619, -0.0342],\n",
      "         [-0.0657,  0.0615,  0.0659,  0.0669,  0.0623, -0.0348],\n",
      "         [-0.0618,  0.0579,  0.0619,  0.0623,  0.0593, -0.0327],\n",
      "         [ 0.0341, -0.0321, -0.0342, -0.0348, -0.0327,  0.0337]],\n",
      "\n",
      "        [[ 0.0068, -0.0067, -0.0066, -0.0066, -0.0066,  0.0024],\n",
      "         [-0.0067,  0.0069,  0.0065,  0.0066,  0.0064, -0.0023],\n",
      "         [-0.0066,  0.0065,  0.0067,  0.0065,  0.0066, -0.0024],\n",
      "         [-0.0066,  0.0066,  0.0065,  0.0067,  0.0062, -0.0024],\n",
      "         [-0.0066,  0.0064,  0.0066,  0.0062,  0.0069, -0.0024],\n",
      "         [ 0.0024, -0.0023, -0.0024, -0.0024, -0.0024,  0.0030]]])\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.70it/s]\n",
      "2020-11-30 18:14:18,305 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_valve_id_00.csv\n",
      "2020-11-30 18:14:18,308 - INFO - AUC : 0.6691150442477877\n",
      "2020-11-30 18:14:18,309 - INFO - pAUC : 0.5556590591523055\n",
      "2020-11-30 18:14:18,310 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:18,310 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_02\n",
      "2020-11-30 18:14:18,315 - INFO - test_file  num : 214\n",
      "2020-11-30 18:14:18,315 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.81it/s]\n",
      "2020-11-30 18:14:18,734 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_valve_id_02.csv\n",
      "2020-11-30 18:14:18,737 - INFO - AUC : 0.45026315789473687\n",
      "2020-11-30 18:14:18,737 - INFO - pAUC : 0.49584487534626037\n",
      "2020-11-30 18:14:18,738 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:18,739 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_04\n",
      "2020-11-30 18:14:18,743 - INFO - test_file  num : 214\n",
      "2020-11-30 18:14:18,743 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.67it/s]\n",
      "2020-11-30 18:14:19,175 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_valve_id_04.csv\n",
      "2020-11-30 18:14:19,178 - INFO - AUC : 0.787719298245614\n",
      "2020-11-30 18:14:19,178 - INFO - pAUC : 0.5304709141274239\n",
      "2020-11-30 18:14:19,179 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:19,179 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_06\n",
      "2020-11-30 18:14:19,183 - INFO - test_file  num : 214\n",
      "2020-11-30 18:14:19,184 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.57it/s]\n",
      "2020-11-30 18:14:19,625 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/anomaly_score_valve_id_06.csv\n",
      "2020-11-30 18:14:19,629 - INFO - AUC : 0.6468421052631579\n",
      "2020-11-30 18:14:19,630 - INFO - pAUC : 0.5124653739612188\n",
      "2020-11-30 18:14:19,630 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-11-30 18:14:19,631 - INFO - AUC and pAUC results -> /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3/result/result.csv\n"
     ]
    }
   ],
   "source": [
    "#def run_eval(param, mode):\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# make output result directory\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# load base directory\n",
    "dirs = com.select_dirs(param=param, mode=mode)\n",
    "\n",
    "# initialize lines in csv for AUC and pAUC\n",
    "csv_lines = []\n",
    "\n",
    "\n",
    "# loop of the base directory\n",
    "for idx, target_dir in enumerate(dirs):\n",
    "    com.logger.info(\"===========================\")\n",
    "    com.logger.info(\"[{idx}/{total}] {dirname}\".format(\n",
    "        dirname=target_dir, idx=idx+1, total=len(dirs)))\n",
    "\n",
    "    machine_type = os.path.split(target_dir)[1]\n",
    "\n",
    "    com.logger.info(\"============== MODEL LOAD ==============\")\n",
    "\n",
    "    model_file = \"{model}/{machine_type}_model.pth\".format(\n",
    "        model=param[\"model_directory\"],\n",
    "        machine_type=machine_type)\n",
    "\n",
    "    if not os.path.exists(model_file):\n",
    "        com.logger.error(\"{} model not found \".format(machine_type))\n",
    "        sys.exit(-1)\n",
    "\n",
    "    # define AE model\n",
    "    model = Model(sample_rate=config['preprocessing']['sample_rate'],\n",
    "                  window_size=config['preprocessing']['window_size'],\n",
    "                  hop_size=config['preprocessing']['hop_size'],\n",
    "                  mel_bins=config['preprocessing']['mel_bins'],\n",
    "                  fmin=config['preprocessing']['fmin'],\n",
    "                  fmax=config['preprocessing']['fmax'],\n",
    "                  latent_size=config['fit']['latent_size'],\n",
    "                  mixture_size=config['fit']['mixture_size']).to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    if mode:\n",
    "        # results by type\n",
    "        csv_lines.append([machine_type])\n",
    "        csv_lines.append([\"id\", \"AUC\", \"pAUC\"])\n",
    "        performance = []\n",
    "\n",
    "    machine_id_list = eval_func.get_machine_id_list_for_test(target_dir)\n",
    "    recons_outpath = RECONS_OUTDIR + '/' + machine_type\n",
    "    os.makedirs(recons_outpath, exist_ok=True)\n",
    "    \n",
    "    # calc train GMM param\n",
    "    com.logger.info(f\"============== CALC GMM PARAM : {machine_type} ==============\")\n",
    "    \n",
    "    train_loader = make_dataloader_test(train_paths[machine_type]['train'])\n",
    "    N = 0\n",
    "    mu_sum = 0\n",
    "    cov_sum = 0\n",
    "    gamma_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(train_loader):\n",
    "            input_data = sample['feature']\n",
    "            input_data = to_var(input_data)\n",
    "            nn_out = model(input_data, device)\n",
    "            tr_phi, tr_mu, tr_cov = model.compute_gmm_params(nn_out['z'], nn_out['gamma'])\n",
    "            tr_phi, tr_mu, tr_cov = tr_phi.to('cpu'), tr_mu.to('cpu'), tr_cov.to('cpu')\n",
    "            batch_gamma_sum = torch.sum(nn_out['gamma'].to('cpu'), dim=0).to('cpu')\n",
    "            gamma_sum += batch_gamma_sum\n",
    "            mu_sum += tr_mu * batch_gamma_sum.unsqueeze(-1) # keep sums of the numerator only\n",
    "            cov_sum += tr_cov * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1) # keep sums of the numerator only\n",
    "            N += input_data.size(0)\n",
    "    train_phi = gamma_sum / N\n",
    "    train_mu = mu_sum / gamma_sum.unsqueeze(-1)\n",
    "    train_cov = cov_sum / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "    print(\"N:\",N)\n",
    "    print(\"phi :\\n\",train_phi)\n",
    "    print(\"mu :\\n\",train_mu)\n",
    "    print(\"cov :\\n\",train_cov)\n",
    "    \n",
    "    # evaluation\n",
    "    for id_str in machine_id_list:\n",
    "\n",
    "        # load list of test files\n",
    "        test_files, y_true = eval_func.test_file_list_generator(target_dir, id_str, mode)\n",
    "\n",
    "        # setup anomaly score file path\n",
    "        anomaly_score_csv = \\\n",
    "            \"{result}/anomaly_score_{machine_type}_{id_str}.csv\"\\\n",
    "            .format(result=param[\"result_directory\"],\n",
    "                    machine_type=machine_type,\n",
    "                    id_str=id_str)\n",
    "        anomaly_score_list = []\n",
    "\n",
    "        com.logger.info(\n",
    "            \"============== BEGIN TEST FOR A MACHINE ID ==============\")\n",
    "\n",
    "        y_pred = []\n",
    "        anomaly_count = 0\n",
    "        normal_count = 0\n",
    "        \n",
    "        test_loader = make_dataloader_test(test_files)\n",
    "        start_idx = 0\n",
    "        end_idx = 0\n",
    "        slicing = None\n",
    "        with torch.no_grad():\n",
    "            for it, data in enumerate(tqdm(test_loader)):\n",
    "                try:\n",
    "                    feature = data['feature']\n",
    "                    feature = to_var(feature)\n",
    "                    label = data['label']\n",
    "                    file_path = data['wav_name']\n",
    "                    # reconstruction through auto encoder in pytorch\n",
    "                    with torch.no_grad():\n",
    "                        nn_out = model(feature)\n",
    "                        z, _ = nn_out['z'], nn_out['gamma']\n",
    "                        sample_energy, cov_diag = model.compute_energy(z, phi=to_var(train_phi), mu=to_var(train_mu), cov=to_var(train_cov), size_average=False)\n",
    "                        preds = sample_energy.data.cpu().numpy()\n",
    "                        if it == 0:\n",
    "                            y_pred = preds.copy()\n",
    "                        else:\n",
    "                            y_pred = np.concatenate([y_pred, preds], axis=0)\n",
    "\n",
    "                    for idx in range(len(file_path)):\n",
    "                        anomaly_score_list.append([os.path.basename(file_path[idx]), preds[idx]])\n",
    "                except FileNotFoundError:\n",
    "                    com.logger.error(\"file broken!!\")\n",
    "\n",
    "        # save anomaly score\n",
    "        eval_func.save_csv(save_file_path=anomaly_score_csv,\n",
    "                           save_data=anomaly_score_list)\n",
    "        com.logger.info(\n",
    "            \"anomaly score result ->  {}\".format(anomaly_score_csv))\n",
    "\n",
    "        if mode:\n",
    "            # append AUC and pAUC to lists\n",
    "            auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "            p_auc = metrics.roc_auc_score(\n",
    "                y_true, y_pred, max_fpr=config[\"etc\"][\"max_fpr\"])\n",
    "            csv_lines.append([id_str.split(\"_\", 1)[1], auc, p_auc])\n",
    "            performance.append([auc, p_auc])\n",
    "            com.logger.info(\"AUC : {}\".format(auc))\n",
    "            com.logger.info(\"pAUC : {}\".format(p_auc))\n",
    "\n",
    "        com.logger.info(\n",
    "            \"============ END OF TEST FOR A MACHINE ID ============\")\n",
    "\n",
    "    if mode:\n",
    "        # calculate averages for AUCs and pAUCs\n",
    "        averaged_performance = numpy.mean(\n",
    "            numpy.array(performance, dtype=float), axis=0)\n",
    "        csv_lines.append([\"Average\"] + list(averaged_performance))\n",
    "        csv_lines.append([])\n",
    "\n",
    "if mode:\n",
    "    # output results\n",
    "    result_path = \"{result}/{file_name}\".format(\n",
    "        result=param[\"result_directory\"],\n",
    "        file_name=param[\"result_file\"])\n",
    "    com.logger.info(\"AUC and pAUC results -> {}\".format(result_path))\n",
    "    eval_func.save_csv(save_file_path=result_path, save_data=csv_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
