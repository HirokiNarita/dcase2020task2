{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show reconstruct image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiroki/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# load config\n",
    "########################################################################\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting I/O path\n",
    "########################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_path = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_path = INPUT_ROOT + \"/add_dev_data\"\n",
    "eval_path = INPUT_ROOT + \"/eval_test\"\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "# machine type\n",
    "MACHINE_TYPE = config['IO_OPTION']['MACHINE_TYPE']\n",
    "machine_types = os.listdir(dev_path)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "RESULT_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/result'\n",
    "RECONS_OUTDIR = OUTPUT_ROOT +'/eval_reconstruct_img'\n",
    "PKL_DIR = OUTPUT_ROOT +'/pkl'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# import default python-library\n",
    "########################################################################\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import itertools\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional python-library\n",
    "########################################################################\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "import common as com\n",
    "import pytorch_modeler as modeler\n",
    "from pytorch_model import DAGMM as Model\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "yaml.warnings({'YAMLLoadWarning': False})\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "########################################################################\n",
    "import eval_functions as eval_func\n",
    "from pytorch_utils import to_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiroki/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# load config\n",
    "########################################################################\n",
    "with open(\"./config.yaml\", 'rb') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting seed\n",
    "########################################################################\n",
    "modeler.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Setting I/O path\n",
    "########################################################################\n",
    "# input dirs\n",
    "INPUT_ROOT = config['IO_OPTION']['INPUT_ROOT']\n",
    "dev_path = INPUT_ROOT + \"/dev_data\"\n",
    "add_dev_path = INPUT_ROOT + \"/add_dev_data\"\n",
    "eval_path = INPUT_ROOT + \"/eval_test\"\n",
    "MODEL_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/models'\n",
    "# machine type\n",
    "MACHINE_TYPE = config['IO_OPTION']['MACHINE_TYPE']\n",
    "machine_types = os.listdir(dev_path)\n",
    "# output dirs\n",
    "OUTPUT_ROOT = config['IO_OPTION']['OUTPUT_ROOT']\n",
    "RESULT_DIR = config['IO_OPTION']['OUTPUT_ROOT'] + '/result'\n",
    "RECONS_OUTDIR = OUTPUT_ROOT +'/eval_reconstruct_img'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# for original function\n",
    "########################################################################\n",
    "param = {}\n",
    "param[\"dev_directory\"] = dev_path\n",
    "param[\"eval_directory\"] = eval_path\n",
    "param[\"model_directory\"] = MODEL_DIR\n",
    "param[\"result_directory\"] = RESULT_DIR\n",
    "param[\"result_file\"] = 'result.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def calc_time_anomaly(x, y, label, file_name):\n",
    "    fig = plt.figure(figsize=(10,5)) # width, height\n",
    "    fig.suptitle('label={}'.format(int(label)))\n",
    "    time_anomaly = np.zeros((x.shape[0]))\n",
    "    for frame in range(x.shape[0]):\n",
    "        time_anomaly[frame] = mse(y[frame,:],x[frame,:])\n",
    "    plt.plot(time_anomaly)\n",
    "    plt.title(f'label:{label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_anomaly.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(time_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(np.abs(x-y), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reconstruct_img(x, y, label, file_name):\n",
    "    fig = plt.figure(figsize=(10,5)) # width, height\n",
    "    fig.suptitle('label={}'.format(int(label)))\n",
    "    ax1 = fig.add_subplot(121, title='x') # 明示的にAxesを作成する\n",
    "    sns.heatmap(x.T, ax=ax1) # ax1を参照するようにする\n",
    "    ax2 = fig.add_subplot(122, title='y')\n",
    "    sns.heatmap(y.T, ax=ax2)\n",
    "    fig.savefig('{}.png'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import preprocessing as prep\n",
    "\n",
    "class extract_waveform(object):\n",
    "    \"\"\"\n",
    "    wavデータロード(波形)\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    sound_data : waveform\n",
    "    \"\"\"\n",
    "    def __init__(self, sound_data=None):\n",
    "        self.sound_data = sound_data\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        self.sound_data = com.file_load(sample['wav_name'],\n",
    "                                        sr=config['preprocessing']['sample_rate'],\n",
    "                                        mono=config['preprocessing']['mono'])\n",
    "        self.sound_data = self.sound_data[0]\n",
    "        self.label = np.array(sample['label'])\n",
    "        self.wav_name = sample['wav_name']\n",
    "        \n",
    "        return {'feature': self.sound_data, 'label': self.label, 'wav_name': self.wav_name}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        feature, label, wav_name = sample['feature'], sample['label'], sample['wav_name']\n",
    "        \n",
    "        return {'feature': torch.from_numpy(feature).float(), 'label': torch.from_numpy(label), 'wav_name': wav_name}\n",
    "\n",
    "class DCASE_task2_Dataset_test(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Attribute\n",
    "    ----------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_list = file_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        # ファイル名でlabelを判断\n",
    "        if \"normal\" in file_path:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        sample = {'wav_name':file_path, 'label':np.array(label)}\n",
    "        sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "def make_dataloader_train(paths):\n",
    "    transform = transforms.Compose([\n",
    "        extract_waveform(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    dataset = DCASE_task2_Dataset_test(paths, transform=transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config['fit']['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return test_loader\n",
    "    \n",
    "def make_dataloader_test(paths):\n",
    "    transform = transforms.Compose([\n",
    "        extract_waveform(),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    dataset = DCASE_task2_Dataset_test(paths, transform=transform)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=config['fit']['batch_size'],\n",
    "        shuffle=True\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "        )\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# make path set and train/valid split\n",
    "############################################################################\n",
    "'''\n",
    "train_paths[machine_type]['train' or 'valid'] = path\n",
    "'''\n",
    "dev_train_paths = {}\n",
    "add_train_paths = {}\n",
    "train_paths = {}\n",
    "\n",
    "for machine_type in machine_types:\n",
    "    # dev train\n",
    "    dev_train_paths = [\"{}/{}/train/\".format(dev_path, machine_type) + file for file in os.listdir(\"{}/{}/train\".format(dev_path, machine_type))]\n",
    "    dev_train_paths = sorted(dev_train_paths)\n",
    "    # add_dev train\n",
    "    add_train_paths = [\"{}/{}/train/\".format(add_dev_path, machine_type) + file for file in os.listdir(\"{}/{}/train\".format(add_dev_path, machine_type))]\n",
    "    add_train_paths = sorted(add_train_paths)\n",
    "    # valid\n",
    "    dev_valid_paths = [\"{}/{}/test/\".format(dev_path, machine_type) + file for file in os.listdir(\"{}/{}/test\".format(dev_path, machine_type))]\n",
    "    dev_valid_paths = sorted(dev_valid_paths)\n",
    "    \n",
    "    train_paths[machine_type] = {}\n",
    "    train_paths[machine_type]['train'] = dev_train_paths + add_train_paths\n",
    "    train_paths[machine_type]['valid'] = dev_valid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_base_path = '/media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.split(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-02 14:32:23,488 - INFO - load_directory <- development\n",
      "2020-12-02 14:32:23,490 - INFO - ===========================\n",
      "2020-12-02 14:32:23,491 - INFO - [1/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar\n",
      "2020-12-02 14:32:23,491 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:25,527 - INFO - ============== CALC GMM PARAM : ToyCar ==============\n",
      "2020-12-02 14:32:25,529 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_01\n",
      "2020-12-02 14:32:25,537 - INFO - test_file  num : 601\n",
      "2020-12-02 14:32:25,538 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.50it/s]\n",
      "2020-12-02 14:32:26,663 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyCar_id_01.csv\n",
      "2020-12-02 14:32:26,666 - INFO - AUC : 0.8090552077404668\n",
      "2020-12-02 14:32:26,667 - INFO - pAUC : 0.54274076507893\n",
      "2020-12-02 14:32:26,667 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:26,668 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_02\n",
      "2020-12-02 14:32:26,680 - INFO - test_file  num : 602\n",
      "2020-12-02 14:32:26,681 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.26it/s]\n",
      "2020-12-02 14:32:27,483 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyCar_id_02.csv\n",
      "2020-12-02 14:32:27,486 - INFO - AUC : 0.47625283446712013\n",
      "2020-12-02 14:32:27,486 - INFO - pAUC : 0.50744917850181\n",
      "2020-12-02 14:32:27,487 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:27,487 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_03\n",
      "2020-12-02 14:32:27,497 - INFO - test_file  num : 602\n",
      "2020-12-02 14:32:27,497 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  5.87it/s]\n",
      "2020-12-02 14:32:28,352 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyCar_id_03.csv\n",
      "2020-12-02 14:32:28,355 - INFO - AUC : 0.39204081632653065\n",
      "2020-12-02 14:32:28,356 - INFO - pAUC : 0.48666897506925205\n",
      "2020-12-02 14:32:28,356 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:28,357 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyCar_id_04\n",
      "2020-12-02 14:32:28,364 - INFO - test_file  num : 602\n",
      "2020-12-02 14:32:28,365 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.37it/s]\n",
      "2020-12-02 14:32:29,153 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyCar_id_04.csv\n",
      "2020-12-02 14:32:29,156 - INFO - AUC : 0.5276757369614512\n",
      "2020-12-02 14:32:29,157 - INFO - pAUC : 0.5179655870445344\n",
      "2020-12-02 14:32:29,157 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:29,158 - INFO - ===========================\n",
      "2020-12-02 14:32:29,159 - INFO - [2/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor\n",
      "2020-12-02 14:32:29,160 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:31,030 - INFO - ============== CALC GMM PARAM : ToyConveyor ==============\n",
      "2020-12-02 14:32:31,032 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_01\n",
      "2020-12-02 14:32:31,043 - INFO - test_file  num : 1181\n",
      "2020-12-02 14:32:31,044 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.47it/s]\n",
      "2020-12-02 14:32:32,594 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyConveyor_id_01.csv\n",
      "2020-12-02 14:32:32,597 - INFO - AUC : 0.41426181102362203\n",
      "2020-12-02 14:32:32,597 - INFO - pAUC : 0.49535332851195457\n",
      "2020-12-02 14:32:32,598 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:32,599 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_02\n",
      "2020-12-02 14:32:32,610 - INFO - test_file  num : 1136\n",
      "2020-12-02 14:32:32,611 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.57it/s]\n",
      "2020-12-02 14:32:34,584 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyConveyor_id_02.csv\n",
      "2020-12-02 14:32:34,587 - INFO - AUC : 0.5070293898809524\n",
      "2020-12-02 14:32:34,588 - INFO - pAUC : 0.4932937813283208\n",
      "2020-12-02 14:32:34,589 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:34,589 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/ToyConveyor_id_03\n",
      "2020-12-02 14:32:34,601 - INFO - test_file  num : 1135\n",
      "2020-12-02 14:32:34,602 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.91it/s]\n",
      "2020-12-02 14:32:35,909 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_ToyConveyor_id_03.csv\n",
      "2020-12-02 14:32:35,913 - INFO - AUC : 0.5077198432564516\n",
      "2020-12-02 14:32:35,914 - INFO - pAUC : 0.5011308424570198\n",
      "2020-12-02 14:32:35,915 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:35,916 - INFO - ===========================\n",
      "2020-12-02 14:32:35,916 - INFO - [3/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan\n",
      "2020-12-02 14:32:35,917 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:36,758 - INFO - ============== CALC GMM PARAM : fan ==============\n",
      "2020-12-02 14:32:36,759 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_00\n",
      "2020-12-02 14:32:36,765 - INFO - test_file  num : 489\n",
      "2020-12-02 14:32:36,766 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.93it/s]\n",
      "2020-12-02 14:32:38,138 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_fan_id_00.csv\n",
      "2020-12-02 14:32:38,140 - INFO - AUC : 0.9280719794344473\n",
      "2020-12-02 14:32:38,141 - INFO - pAUC : 0.8205926126369909\n",
      "2020-12-02 14:32:38,141 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:38,142 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_02\n",
      "2020-12-02 14:32:38,147 - INFO - test_file  num : 441\n",
      "2020-12-02 14:32:38,148 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.75it/s]\n",
      "2020-12-02 14:32:39,217 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_fan_id_02.csv\n",
      "2020-12-02 14:32:39,220 - INFO - AUC : 0.7027272727272728\n",
      "2020-12-02 14:32:39,221 - INFO - pAUC : 0.7359160364253743\n",
      "2020-12-02 14:32:39,222 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:39,222 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_04\n",
      "2020-12-02 14:32:39,229 - INFO - test_file  num : 430\n",
      "2020-12-02 14:32:39,230 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.62it/s]\n",
      "2020-12-02 14:32:40,339 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_fan_id_04.csv\n",
      "2020-12-02 14:32:40,342 - INFO - AUC : 0.5021363636363636\n",
      "2020-12-02 14:32:40,342 - INFO - pAUC : 0.5014702950558214\n",
      "2020-12-02 14:32:40,343 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:40,343 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/fan_id_06\n",
      "2020-12-02 14:32:40,351 - INFO - test_file  num : 443\n",
      "2020-12-02 14:32:40,351 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.33it/s]\n",
      "2020-12-02 14:32:41,554 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_fan_id_06.csv\n",
      "2020-12-02 14:32:41,557 - INFO - AUC : 0.847128279883382\n",
      "2020-12-02 14:32:41,558 - INFO - pAUC : 0.8443302132883228\n",
      "2020-12-02 14:32:41,558 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:41,558 - INFO - ===========================\n",
      "2020-12-02 14:32:41,559 - INFO - [4/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump\n",
      "2020-12-02 14:32:41,560 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:42,397 - INFO - ============== CALC GMM PARAM : pump ==============\n",
      "2020-12-02 14:32:42,399 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_00\n",
      "2020-12-02 14:32:42,402 - INFO - test_file  num : 237\n",
      "2020-12-02 14:32:42,403 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.92it/s]\n",
      "2020-12-02 14:32:42,916 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_pump_id_00.csv\n",
      "2020-12-02 14:32:42,919 - INFO - AUC : 0.7279562043795619\n",
      "2020-12-02 14:32:42,919 - INFO - pAUC : 0.6534767575873992\n",
      "2020-12-02 14:32:42,920 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:42,920 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_02\n",
      "2020-12-02 14:32:42,923 - INFO - test_file  num : 205\n",
      "2020-12-02 14:32:42,924 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n",
      "2020-12-02 14:32:43,854 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_pump_id_02.csv\n",
      "2020-12-02 14:32:43,857 - INFO - AUC : 0.6050476190476191\n",
      "2020-12-02 14:32:43,858 - INFO - pAUC : 0.6270676691729323\n",
      "2020-12-02 14:32:43,859 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:43,859 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_04\n",
      "2020-12-02 14:32:43,863 - INFO - test_file  num : 194\n",
      "2020-12-02 14:32:43,864 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.56it/s]\n",
      "2020-12-02 14:32:44,306 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_pump_id_04.csv\n",
      "2020-12-02 14:32:44,309 - INFO - AUC : 0.8458510638297873\n",
      "2020-12-02 14:32:44,309 - INFO - pAUC : 0.8376259798432251\n",
      "2020-12-02 14:32:44,310 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:44,311 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/pump_id_06\n",
      "2020-12-02 14:32:44,314 - INFO - test_file  num : 196\n",
      "2020-12-02 14:32:44,315 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.66it/s]\n",
      "2020-12-02 14:32:44,864 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_pump_id_06.csv\n",
      "2020-12-02 14:32:44,867 - INFO - AUC : 0.6714583333333333\n",
      "2020-12-02 14:32:44,868 - INFO - pAUC : 0.6019736842105263\n",
      "2020-12-02 14:32:44,868 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:44,869 - INFO - ===========================\n",
      "2020-12-02 14:32:44,870 - INFO - [5/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider\n",
      "2020-12-02 14:32:44,870 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:45,727 - INFO - ============== CALC GMM PARAM : slider ==============\n",
      "2020-12-02 14:32:45,728 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_00\n",
      "2020-12-02 14:32:45,733 - INFO - test_file  num : 445\n",
      "2020-12-02 14:32:45,733 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  6.18it/s]\n",
      "2020-12-02 14:32:46,385 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_slider_id_00.csv\n",
      "2020-12-02 14:32:46,388 - INFO - AUC : 0.39504347826086955\n",
      "2020-12-02 14:32:46,388 - INFO - pAUC : 0.4897025171624714\n",
      "2020-12-02 14:32:46,389 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:46,390 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_02\n",
      "2020-12-02 14:32:46,396 - INFO - test_file  num : 356\n",
      "2020-12-02 14:32:46,397 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.55it/s]\n",
      "2020-12-02 14:32:46,941 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_slider_id_02.csv\n",
      "2020-12-02 14:32:46,944 - INFO - AUC : 0.22013671875000002\n",
      "2020-12-02 14:32:46,945 - INFO - pAUC : 0.5027754934210527\n",
      "2020-12-02 14:32:46,945 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:46,946 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_04\n",
      "2020-12-02 14:32:46,950 - INFO - test_file  num : 267\n",
      "2020-12-02 14:32:46,951 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.03it/s]\n",
      "2020-12-02 14:32:47,451 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_slider_id_04.csv\n",
      "2020-12-02 14:32:47,455 - INFO - AUC : 0.56437125748503\n",
      "2020-12-02 14:32:47,456 - INFO - pAUC : 0.5445950204853451\n",
      "2020-12-02 14:32:47,457 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:47,457 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/slider_id_06\n",
      "2020-12-02 14:32:47,462 - INFO - test_file  num : 178\n",
      "2020-12-02 14:32:47,463 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.06it/s]\n",
      "2020-12-02 14:32:47,861 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_slider_id_06.csv\n",
      "2020-12-02 14:32:47,864 - INFO - AUC : 0.5\n",
      "2020-12-02 14:32:47,865 - INFO - pAUC : 0.5107962213225371\n",
      "2020-12-02 14:32:47,865 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:47,866 - INFO - ===========================\n",
      "2020-12-02 14:32:47,867 - INFO - [6/6] /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve\n",
      "2020-12-02 14:32:47,867 - INFO - ============== MODEL LOAD ==============\n",
      "2020-12-02 14:32:48,681 - INFO - ============== CALC GMM PARAM : valve ==============\n",
      "2020-12-02 14:32:48,682 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_00\n",
      "2020-12-02 14:32:48,685 - INFO - test_file  num : 213\n",
      "2020-12-02 14:32:48,686 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.90it/s]\n",
      "2020-12-02 14:32:49,202 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_valve_id_00.csv\n",
      "2020-12-02 14:32:49,205 - INFO - AUC : 0.5101327433628319\n",
      "2020-12-02 14:32:49,205 - INFO - pAUC : 0.5419189566837448\n",
      "2020-12-02 14:32:49,206 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:49,206 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_02\n",
      "2020-12-02 14:32:49,210 - INFO - test_file  num : 214\n",
      "2020-12-02 14:32:49,211 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n",
      "2020-12-02 14:32:50,139 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_valve_id_02.csv\n",
      "2020-12-02 14:32:50,143 - INFO - AUC : 0.14473684210526316\n",
      "2020-12-02 14:32:50,144 - INFO - pAUC : 0.48130193905817176\n",
      "2020-12-02 14:32:50,144 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:50,145 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_04\n",
      "2020-12-02 14:32:50,148 - INFO - test_file  num : 214\n",
      "2020-12-02 14:32:50,149 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.65it/s]\n",
      "2020-12-02 14:32:50,582 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_valve_id_04.csv\n",
      "2020-12-02 14:32:50,585 - INFO - AUC : 0.537719298245614\n",
      "2020-12-02 14:32:50,585 - INFO - pAUC : 0.5022769243683372\n",
      "2020-12-02 14:32:50,586 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:50,586 - INFO - target_dir : /media/hiroki/working/research/dcase2020/datasets/DCASE2/dev_data/valve_id_06\n",
      "2020-12-02 14:32:50,591 - INFO - test_file  num : 214\n",
      "2020-12-02 14:32:50,592 - INFO - ============== BEGIN TEST FOR A MACHINE ID ==============\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.69it/s]\n",
      "2020-12-02 14:32:51,021 - INFO - anomaly score result ->  /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/anomaly_score_valve_id_06.csv\n",
      "2020-12-02 14:32:51,024 - INFO - AUC : 0.515\n",
      "2020-12-02 14:32:51,025 - INFO - pAUC : 0.5008138903960934\n",
      "2020-12-02 14:32:51,025 - INFO - ============ END OF TEST FOR A MACHINE ID ============\n",
      "2020-12-02 14:32:51,026 - INFO - AUC and pAUC results -> /media/hiroki/working/research/dcase2020/result/2D/DAGMM/strict_comp/latent5_mixture3_ver3/result/result.csv\n"
     ]
    }
   ],
   "source": [
    "#def run_eval(param, mode):\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# make output result directory\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# load base directory\n",
    "dirs = com.select_dirs(param=param, mode=mode)\n",
    "\n",
    "# initialize lines in csv for AUC and pAUC\n",
    "csv_lines = []\n",
    "\n",
    "\n",
    "# loop of the base directory\n",
    "for idx, target_dir in enumerate(dirs):\n",
    "    com.logger.info(\"===========================\")\n",
    "    com.logger.info(\"[{idx}/{total}] {dirname}\".format(\n",
    "        dirname=target_dir, idx=idx+1, total=len(dirs)))\n",
    "\n",
    "    machine_type = os.path.split(target_dir)[1]\n",
    "\n",
    "    com.logger.info(\"============== MODEL LOAD ==============\")\n",
    "\n",
    "    model_file = \"{model}/{machine_type}_model.pth\".format(\n",
    "        model=param[\"model_directory\"],\n",
    "        machine_type=machine_type)\n",
    "\n",
    "    if not os.path.exists(model_file):\n",
    "        com.logger.error(\"{} model not found \".format(machine_type))\n",
    "        sys.exit(-1)\n",
    "\n",
    "    # define AE model\n",
    "    model = Model(sample_rate=config['preprocessing']['sample_rate'],\n",
    "                  window_size=config['preprocessing']['window_size'],\n",
    "                  hop_size=config['preprocessing']['hop_size'],\n",
    "                  mel_bins=config['preprocessing']['mel_bins'],\n",
    "                  fmin=config['preprocessing']['fmin'],\n",
    "                  fmax=config['preprocessing']['fmax'],\n",
    "                  latent_size=config['fit']['latent_size'],\n",
    "                  mixture_size=config['fit']['mixture_size']).to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    if mode:\n",
    "        # results by type\n",
    "        csv_lines.append([machine_type])\n",
    "        csv_lines.append([\"id\", \"AUC\", \"pAUC\"])\n",
    "        performance = []\n",
    "\n",
    "    machine_id_list = eval_func.get_machine_id_list_for_test(target_dir)\n",
    "    recons_outpath = RECONS_OUTDIR + '/' + machine_type\n",
    "    os.makedirs(recons_outpath, exist_ok=True)\n",
    "    \n",
    "    # calc train GMM param\n",
    "    com.logger.info(f\"============== CALC GMM PARAM : {machine_type} ==============\")\n",
    "    \n",
    "    #train_loader = make_dataloader_test(train_paths[machine_type]['train'])\n",
    "    gmm_path = gmm_base_path + f'/{machine_type}_gmm_param.pkl'\n",
    "    gmm_param = pd.read_pickle(gmm_path)\n",
    "    # evaluation\n",
    "    for id_str in machine_id_list:\n",
    "\n",
    "        # load list of test files\n",
    "        test_files, y_true = eval_func.test_file_list_generator(target_dir, id_str, mode)\n",
    "\n",
    "        # setup anomaly score file path\n",
    "        anomaly_score_csv = \\\n",
    "            \"{result}/anomaly_score_{machine_type}_{id_str}.csv\"\\\n",
    "            .format(result=param[\"result_directory\"],\n",
    "                    machine_type=machine_type,\n",
    "                    id_str=id_str)\n",
    "        anomaly_score_list = []\n",
    "\n",
    "        com.logger.info(\n",
    "            \"============== BEGIN TEST FOR A MACHINE ID ==============\")\n",
    "\n",
    "        y_pred = []\n",
    "        anomaly_count = 0\n",
    "        normal_count = 0\n",
    "        \n",
    "        test_loader = make_dataloader_test(test_files)\n",
    "        start_idx = 0\n",
    "        end_idx = 0\n",
    "        slicing = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for it, data in enumerate(tqdm(test_loader)):\n",
    "                try:\n",
    "                    feature = data['feature']\n",
    "                    feature = to_var(feature)\n",
    "                    label = data['label']\n",
    "                    file_path = data['wav_name']\n",
    "                    # reconstruction through auto encoder in pytorch\n",
    "                    with torch.no_grad():\n",
    "                        nn_out = model(feature)\n",
    "                        z, _ = nn_out['z'], nn_out['gamma']\n",
    "                        sample_energy, cov_diag = model.compute_energy(z, phi=gmm_param[0], mu=gmm_param[1], cov=gmm_param[2], size_average=False)\n",
    "                        preds = sample_energy.data.cpu().numpy()\n",
    "                        if it == 0:\n",
    "                            y_pred = preds.copy()\n",
    "                        else:\n",
    "                            y_pred = np.concatenate([y_pred, preds], axis=0)\n",
    "\n",
    "                    for idx in range(len(file_path)):\n",
    "                        anomaly_score_list.append([os.path.basename(file_path[idx]), preds[idx]])\n",
    "                except FileNotFoundError:\n",
    "                    com.logger.error(\"file broken!!\")\n",
    "\n",
    "        # save anomaly score\n",
    "        eval_func.save_csv(save_file_path=anomaly_score_csv,\n",
    "                           save_data=anomaly_score_list)\n",
    "        com.logger.info(\n",
    "            \"anomaly score result ->  {}\".format(anomaly_score_csv))\n",
    "\n",
    "        if mode:\n",
    "            # append AUC and pAUC to lists\n",
    "            auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "            p_auc = metrics.roc_auc_score(\n",
    "                y_true, y_pred, max_fpr=config[\"etc\"][\"max_fpr\"])\n",
    "            csv_lines.append([id_str.split(\"_\", 1)[1], auc, p_auc])\n",
    "            performance.append([auc, p_auc])\n",
    "            com.logger.info(\"AUC : {}\".format(auc))\n",
    "            com.logger.info(\"pAUC : {}\".format(p_auc))\n",
    "\n",
    "        com.logger.info(\n",
    "            \"============ END OF TEST FOR A MACHINE ID ============\")\n",
    "\n",
    "    if mode:\n",
    "        # calculate averages for AUCs and pAUCs\n",
    "        averaged_performance = numpy.mean(\n",
    "            numpy.array(performance, dtype=float), axis=0)\n",
    "        csv_lines.append([\"Average\"] + list(averaged_performance))\n",
    "        csv_lines.append([])\n",
    "\n",
    "if mode:\n",
    "    # output results\n",
    "    result_path = \"{result}/{file_name}\".format(\n",
    "        result=param[\"result_directory\"],\n",
    "        file_name=param[\"result_file\"])\n",
    "    com.logger.info(\"AUC and pAUC results -> {}\".format(result_path))\n",
    "    eval_func.save_csv(save_file_path=result_path, save_data=csv_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
